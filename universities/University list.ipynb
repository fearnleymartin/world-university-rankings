{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import urlparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting a comprehensive list of universities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find list of all countries over the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of all countries of the world from https://en.wikipedia.org/wiki/Education_Index\n",
    "df_ei = pd.read_excel('world_list_education_index.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries_ei = df_ei[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ei[0][168] = 'Switzerland'\n",
    "df_ei[0][122] = 'Nepal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find databases of universities over the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all countries from univ.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_univ_world = requests.get(\"http://univ.cc/world.php\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "univ_soup = BeautifulSoup(html_univ_world, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries_univ = []\n",
    "for option in univ_soup.find_all('option')[1:]:\n",
    "    countries_univ.append(option.text.split(sep='(')[0].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all countries in Shanghai ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_shanghai = requests.get(\"http://www.shanghairanking.com/Search.html\").text\n",
    "shanghai_soup = BeautifulSoup(html_shanghai, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries_shanghai = []\n",
    "for option in shanghai_soup.find_all('option')[1:-1]:\n",
    "    countries_shanghai.append(option.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are all universities over the world represented?\n",
    "\n",
    "Since univ.cc contains the most countries, we first check if all countries contained in the Shanghai ranking are present. Afterwards we verify that the list if very comprehensive by cross checking with the wikipedia education index list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The education index list contains {} countries\".format(len(countries_ei)))\n",
    "print(\"The univ.cc list contains {} countries\".format(len(countries_univ)))\n",
    "print(\"The Shanghai list contains {} countries\".format(len(countries_shanghai)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shanghai = pd.DataFrame(countries_shanghai, columns=['country'])\n",
    "df_shanghai[~df_shanghai.country.isin(countries_univ)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Czech Republic' in countries_univ)\n",
    "print('Hong Kong' in countries_univ)\n",
    "print('Macau' in countries_univ)\n",
    "print('Korea, South' in countries_univ)\n",
    "print('Taiwan' in countries_univ)\n",
    "print('United States is missing because univ.cc has a seperate list for the united states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ei[~df_ei[0].isin(countries_univ)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Brunei' in countries_univ)\n",
    "print('Congo, Republic of the' in countries_univ)\n",
    "print('Congo, Democratic Republic of the' in countries_univ)\n",
    "print('Guinea' in countries_univ)\n",
    "print('Korea, North' in countries_univ)\n",
    "print('Korea, South' in countries_univ)\n",
    "print('Laos' in countries_univ)\n",
    "print('Moldova' in countries_univ)\n",
    "print('Burma' in countries_univ)\n",
    "print('Palestine' in countries_univ)\n",
    "print('Russia' in countries_univ)\n",
    "print('Syria' in countries_univ)\n",
    "print('Macedonia' in countries_univ)\n",
    "\n",
    "print('\\nPalau Community College is a two-year college in the Republic of Palau, and the only school of higher education in the nation, not necesarry to include\\n')\n",
    "\n",
    "print('The University of the South Pacific is a regional university serving 12 member countries: Cook Islands, Fiji Islands, Kiribati, Marshall Islands, Nauru, Niue, Samoa, Solomon Islands, Tokelau, Tonga, Tuvalu and Vanuatu.\\n')\n",
    "\n",
    "print('United States is missing because univ.cc has a seperate list for the united states\\n')\n",
    "\n",
    "print('Only for Timor-Leste and Sao Tome and Principe, which both have 1 university, the country was not found in the univ.cc list which makes it a very comprehensive list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create comprehensive university list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_university_df():\n",
    "    # create list by searching each country seperatly to add country information\n",
    "    base_urls = [\"http://univ.cc/world.php\", \"http://univ.cc/states.php\"]\n",
    "    countries_univ = []\n",
    "    countries_names = []\n",
    "    for i,url in enumerate(base_urls):\n",
    "        r = requests.get(url).text\n",
    "        h = BeautifulSoup(r, 'html.parser')\n",
    "        \n",
    "        for option in h.find_all('option')[1:]:\n",
    "            c = option.text.split(sep='(')[0].strip()\n",
    "            countries_univ.append((c, option['value']))\n",
    "            if i == 1:\n",
    "                countries_names.append(\"United States\")\n",
    "            else:\n",
    "                countries_names.append(c)\n",
    "\n",
    "    search_url = \"http://univ.cc/search.php?dom=\"\n",
    "    next_p = \"&start=\"\n",
    "    step = 50\n",
    "    unis = []\n",
    "    \n",
    "    for i in range(len(countries_univ)):\n",
    "        url = search_url + countries_univ[i][1]\n",
    "        r = requests.get(url).text\n",
    "        h = BeautifulSoup(r, 'html.parser')\n",
    "\n",
    "        for l in h.find_all('li'):\n",
    "            a = l.find('a')\n",
    "            unis.append([countries_names[i], a.text, urlparse(a['href']).netloc])\n",
    "\n",
    "        n = int(h.find('p').text.split(' ')[1])\n",
    "\n",
    "        if n > step:\n",
    "            url = url + next_p\n",
    "            for j in range (step+1, n, step):\n",
    "                url_start = url + str(j)\n",
    "\n",
    "                r = requests.get(url_start).text\n",
    "                h = BeautifulSoup(r, 'html.parser')\n",
    "\n",
    "                for l in h.find_all('li'):\n",
    "                    a = l.find('a')\n",
    "                    unis.append([countries_names[i], a.text, urlparse(a['href']).netloc])\n",
    "                    \n",
    "    df = pd.DataFrame(unis,columns=['Country', 'University', 'Website'])\n",
    "    df.drop_duplicates(subset=['Website'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uni_df = create_university_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uni_df.to_csv('university_list_countries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is it OK to only consider english search terms?\n",
    "Check official languages of the country or by languages the websites is offered in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def provided_languages(website):\n",
    "    if 'http://' not in website:\n",
    "        website = 'http://' + website\n",
    "    \n",
    "    languages = []\n",
    "    try:\n",
    "        r = requests.get(website).text\n",
    "        h = BeautifulSoup(r, 'html.parser')\n",
    "        h.find_all(lambda tag:[languages.append(tag[a]) for a in tag.attrs if 'lang' in a])\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        \n",
    "    result = \",\".join(languages)\n",
    "    print(\"website {}: {}\".format(website, result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uni_df['Website'].apply(provided_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_country_info(unis_df):\n",
    "    country_info = pd.read_csv('CountryInfo.csv', delimiter=\";\")\n",
    "    lang = country_info[['Country','Languages', 'Population', 'Continent']]\n",
    "    return unis_df.merge(lang, how='left', on=\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extra_uni_info = add_country_info(uni_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_filter = np.logical_not(extra_uni_info['Languages'].str.contains('en').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_filtered = extra_uni_info[language_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "website http://www.afghanuniversity.edu.af: \n",
      "website http://www.au.edu.af: en-US\n",
      "website http://www.auaf.edu.af: \n",
      "website http://www.aria.edu.af: en-US\n",
      "website http://www.ariana.edu.af: \n",
      "website http://www.badakhshan.edu.af: \n",
      "website http://www.baghlan.edu.af: fa,fa\n",
      "website http://www.bakhtar.edu.af: \n",
      "HTTPConnectionPool(host='www.ba.edu.af', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x116eb3e10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))\n",
      "website http://www.ba.edu.af: \n",
      "website http://www.bu.edu.af: fa,fa\n",
      "website http://www.bost.edu.af: en-US,en-US\n",
      "website http://www.dawat.edu.af: fa-ir\n",
      "website http://www.dunya.edu.af: en-US\n",
      "website http://www.faryab.edu.af: \n"
     ]
    }
   ],
   "source": [
    "provided_languages = language_filtered['Website'].apply(provided_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
